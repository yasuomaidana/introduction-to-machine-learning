{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Neural Networks\n",
    "This notebook has mixed types of theoretical and code implementation questions on multilayer perceptron and neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pylab as plt\n",
    "import pytest\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1 - Single-Layer and Multilayer Perceptron Learning\n",
    "---\n",
    "\n",
    "**Part A** : Consider learning the following concepts with either a single-layer or multilayer perceptron where all hidden and output neurons utilize *indicator* activation functions. For each of the following concepts, state whether the concept can be learned by a single-layer perceptron. Briefly justify your response by providing weights and biases as applicable:\n",
    "\n",
    "i. $~ \\texttt{ NOT } x_1$\n",
    "\n",
    "ii. $~~x_1 \\texttt{ NOR } x_2$\n",
    "\n",
    "iii. $~~x_1 \\texttt{ XNOR } x_2$ (output 1 when $x_1 = x_2$ and 0 otherwise)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B** : Determine an architecture and specific values of the weights and biases in a single-layer or multilayer perceptron with *indicator* activation functions that can learn $x_1 \\texttt{ XNOR } x_2$. <br>\n",
    "In this week's Peer Review, describe your architecture and state your weight matrices and bias vectors. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then demonstrate that your solution is correct by implementing forward propagation for your network in Python and showing that it correctly produces the correct boolean output values for each of the four possible combinations of $x_1$ and $x_2$. <br>\n",
    "By reading [Neural Representation of AND, OR, NOT, XOR and XNOR Logic Gates](https://medium.com/@stanleydukor/neural-representation-of-and-or-not-xor-and-xnor-logic-gates-perceptron-algorithm-b0275375fea1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By considering the following thruth tabel <br>\n",
    "![XNOR truth tabel](https://miro.medium.com/v2/resize:fit:598/0*oGu2x1DA9soE3IdO.gif) <br>\n",
    "And the following neural network <br>\n",
    "![XNOR neural network](https://miro.medium.com/v2/resize:fit:640/format:webp/1*yZfw_9DRMephzZwejjhyTA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| a | b | nor(and,nor) => xor\n",
      "| 0 | 0 | nor(  0,  1) =>   0\n",
      "| 0 | 1 | nor(  0,  0) =>   1\n",
      "| 1 | 0 | nor(  0,  0) =>   1\n",
      "| 1 | 1 | nor(  1,  0) =>   0\n"
     ]
    }
   ],
   "source": [
    "# implement forward propagation for network\n",
    "# show that it correctly produces the correct boolean output values \n",
    "# for each of the four possible combinations of x1 and x2 \n",
    "\n",
    "def neuron(X:np.array, W:np.array, b:float):\n",
    "    return activation(X@W + b)\n",
    "# Initialize x with the 4 possible combinations of 0 and 1 to generate 4 values for y(output)\n",
    "def activation(x):\n",
    "    return 1 if x>0 else 0\n",
    "def and_neuron(X:np.array):\n",
    "    b = -1\n",
    "    W = np.array([1,1])\n",
    "    return neuron(X,W,b)\n",
    "def not_neuron(X):\n",
    "    W = np.array([-1])\n",
    "    X = np.array([X])\n",
    "    return neuron(X,W,1)\n",
    "def nor_neuron(X:np.array):\n",
    "    W = np.array([-1,-1])\n",
    "    b = 1\n",
    "    return neuron(X,W,b)\n",
    "def xor_neuron(X:np.array):\n",
    "    x1 = and_neuron(X)\n",
    "    x2 = nor_neuron(X)\n",
    "    return nor_neuron(np.array([x1,x2]))\n",
    "def convert_to_array(i):\n",
    "    raw = [int(j) for j in f\"{i:02b}\"]\n",
    "    return np.array(raw)\n",
    "\n",
    "\n",
    "combinations = [ convert_to_array(i) for i in range(4)]\n",
    "table_format = \"| {:1} | {:1} | nor({:3},{:3}) => {:3}\"\n",
    "header = table_format.format(\"a\",\"b\", \"and\", \"nor\", \"xor\")\n",
    "print(header)\n",
    "for i in combinations:\n",
    "    print(table_format.format(i[0], i[1], and_neuron(i), nor_neuron(i), xor_neuron(i)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
