
## Books

[Jurafsky & Martin's Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/)

## Jurafsky & Martin's Speech and Language Processing Chapters of interest

- Jurafsky & Martin's Speech and Language Processing - Chapter 3 **n-gram language models.**


## Articles

[How to generate text: using different decoding methods for language generation with Transformers - Hugging Face](https://huggingface.co/blog/how-to-generate)
[The Illustrated GPT-2 (Visualizing Transformer Language Models) - Jay Alammar](https://jalammar.github.io/illustrated-gpt2/)
[Evaluating Large Language Model (LLM) systems: Metrics, challenges, and best practices](https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5)

[LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971)
[Llama 2: Open Foundation and Fine-Tuned ChatModels](https://arxiv.org/pdf/2307.09288)
[The Llama 3 Herd of Models](https://scontent.fntr5-1.fna.fbcdn.net/v/t39.2365-6/468347782_9231729823505907_4580471254289036098_n.pdf?_nc_cat=110&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=5kRJL7FdO8sQ7kNvwGus8LW&_nc_oc=Adlzj7l8dbUceLDwnTdjHjsoFO9Eu3xzFh1zL_bLRsLVD2UGvePCIBpaCVD1Hj5A-G4&_nc_zt=14&_nc_ht=scontent.fntr5-1.fna&_nc_gid=AHKTOMEUfwsAZxx2fRP6_Q&oh=00_AfLn5VGafXxBz5CQBBoR_ZI-ngp2W3fZ3GmTgF5VOWKyQw&oe=68229E80)


## Important Papers

[Attention Is All You Need](https://arxiv.org/pdf/1706.03762)
[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805v2)

## Vision papers 
[You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640)
[A COMPREHENSIVE REVIEW OF YOLO ARCHITECTURES IN COMPUTER VISION: FROM YOLOV1 TO YOLOV8 AND YOLO-NAS](https://arxiv.org/pdf/2304.00501)



