{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26863232",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "Adapt the CNN example for MNIST digit classfication from Notebook 3A. Feel free to play around with the model architecture and see how the training time/performance changes, but to begin, try the following:\n",
    "\n",
    "Image ->\n",
    "convolution (32 3x3 filters) -> nonlinearity (ReLU) ->\n",
    "convolution (32 3x3 filters) -> nonlinearity (ReLU) -> (2x2 max pool) ->\n",
    "convolution (64 3x3 filters) -> nonlinearity (ReLU) ->\n",
    "convolution (64 3x3 filters) -> nonlinearity (ReLU) -> (2x2 max pool) -> flatten -> fully connected (256 hidden units) -> nonlinearity (ReLU) ->\n",
    "fully connected (10 hidden units) -> softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de2a9cb",
   "metadata": {},
   "source": [
    "## Dimensions calculation\n",
    "See [l1](https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d) and [l2](https://aldozaimi.wordpress.com/2020/02/13/determine-the-number-of-trainable-parameters-in-a-neural-network/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c74293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions calculator\n",
    "def w_out(w_in, k, p,s=1):\n",
    "    return (w_in-k+2*p)/s+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47c1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convolutional model\n",
    "import torch.nn as nn\n",
    "\n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(7*7*64, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        # conv layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        # fc layer 1\n",
    "        x = x.view(-1, 7*7*64)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # fc layer 2\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27057642",
   "metadata": {},
   "source": [
    "Here I only use three [epochs](https://www.simplilearn.com/tutorials/machine-learning-tutorial/what-is-epoch-in-machine-learning#:~:text=An%20epoch%20is%20when%20all,dataset%20takes%20around%20an%20algorithm.).\n",
    "\n",
    "> An epoch is when all the training data is used at once and is defined as the total number of iterations of all the training data in one cycle for training the machine learning model. \n",
    "Another way to define an epoch is the number of passes a training dataset takes around an algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100c8020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40948166002e46a1abace1e3ebc49d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066f4602d84d4014a98f1116c32901cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60113f4968d04d25ae9846352aae965f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e7d3b6dc2141fabb09e3d8c15a0e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb56e25d7ab4450a3976d3f9a7a0aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9873999953269958\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# Load the data\n",
    "mnist_train = datasets.MNIST(root=\"./datasets\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root=\"./datasets\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=100, shuffle=False)\n",
    "\n",
    "## Training\n",
    "# Instantiate model  \n",
    "model = MNIST_CNN()  # <---- change here\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # <---- change here\n",
    "\n",
    "\n",
    "# Iterate through train set minibatchs \n",
    "for epoch in trange(3): \n",
    "    for images, labels in tqdm(train_loader):\n",
    "        # Zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        x = images  # <---- change here \n",
    "        y = model(x)\n",
    "        loss = criterion(y, labels)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "## Testing\n",
    "correct = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Iterate through test set minibatchs \n",
    "    for images, labels in tqdm(test_loader):\n",
    "        # Forward pass\n",
    "        x = images  # <---- change here \n",
    "        y = model(x)\n",
    "\n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        correct += torch.sum((predictions == labels).float())\n",
    "\n",
    "print('Test accuracy: {}'.format(correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e361be",
   "metadata": {},
   "source": [
    "## Short answer\n",
    "1. How does the CNN compare in accuracy with yesterday's logistic regression and MLP models? How about training time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0c7beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It increases its accuracy by 7.340002059936523. However, the training time is a bit slower\n"
     ]
    }
   ],
   "source": [
    "old_accuracy = 0.914\n",
    "new_accuracy = correct/total\n",
    "accuracy_ratio = new_accuracy-old_accuracy\n",
    "print(\"It increases its accuracy by {}. However, the training time is a bit slower\".format(accuracy_ratio*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30cd471",
   "metadata": {},
   "source": [
    "2. How many trainable parameters are there in the CNN you built for this assignment?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c070e7",
   "metadata": {},
   "source": [
    "### CONV Layer\n",
    "This is where CNN learns, so certainly we’ll have weight matrices. To calculate the learnable parameters here, all we have to do is just multiply the by the shape of width $w$, height $h$, previous layer’s filters (*channels*) $d$ and account for all such filters $k$ (*channels*) in the current layer. Don’t forget the bias term for each of the filter. Number of parameters in a CONV layer would be : $((m * n * d)+1)* k)$, added $1$ because of the bias term for each filter. The same expression can be written as follows: **((shape of width of the filter * shape of height of the filter * number of filters in the previous layer+1)*number of filters)**. Where the term “filter” refer to the number of filters in the current layer.\n",
    "\n",
    "### Fully connected\n",
    "For the fully connected layers, the number of trainable parameters can be computed by $(n + 1) × m$, where $n$ is the number of input units and $m$ is the number of output units. The $+1$ term in the equation takes into account the bias terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a4182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_conv(w,h,d,k):\n",
    "    return ((w*h*d)+1)*k\n",
    "def learn_full(n,m):\n",
    "    return (n+1)*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b460b4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It has 824458 parameters. which is 7.8013834085597225 times larger than the multilayer perceptron\n"
     ]
    }
   ],
   "source": [
    "c1 = learn_conv(3,3,1,32)\n",
    "c2 = learn_conv(3,3,32,64)\n",
    "f1 = learn_full(7*7*64,256)\n",
    "f2 = learn_full(256,10)\n",
    "total_parameters = c1+c2+f1+f2\n",
    "old_parameters = 105681\n",
    "paremeters_ratio = total_parameters/old_parameters\n",
    "print(\"It has {} parameters. which is {} times larger than the multilayer perceptron\".format(total_parameters,paremeters_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bafbc1",
   "metadata": {},
   "source": [
    "3\\. When would you use a CNN versus a logistic regression model or an MLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed31c9",
   "metadata": {},
   "source": [
    "Use MLPs For:\n",
    "\n",
    "* Tabular datasets\n",
    "* Classification prediction problems\n",
    "* Regression prediction problems\n",
    "\n",
    "They are very flexible and can be used generally to **learn a mapping from inputs to outputs**.\n",
    "\n",
    "This flexibility allows them to be applied to other types of data. For example, the pixels of an image can be reduced down to one long row of data and fed into a MLP. The words of a document can also be reduced to one long row of data and fed to a MLP. Even the lag observations for a time series prediction problem can be reduced to a long row of data and fed to a MLP.\n",
    "\n",
    "As such, if your data is in a form other than a tabular dataset, such as an image, document, or time series, I would recommend at least testing an MLP on your problem. The results can be used as a baseline point of comparison to confirm that other models that may appear better suited add value.\n",
    "\n",
    "Use CNNs For:\n",
    "\n",
    "* Image data\n",
    "* Classification prediction problems\n",
    "* Regression prediction problems\n",
    "\n",
    "More generally, CNNs work well with data that has a spatial relationship.\n",
    "\n",
    "The CNN input is **traditionally two-dimensional, a field or matrix**, but can also be changed to be one-dimensional, allowing it to develop an internal representation of a one-dimensional sequence.\n",
    "\n",
    "This allows the CNN to be used more generally on other types of data that has a spatial relationship. For example, there is an order relationship between words in a document of text. There is an ordered relationship in the time steps of a time series.\n",
    "\n",
    "Although not specifically developed for non-image data, CNNs achieve state-of-the-art results on problems such as document classification used in sentiment analysis and related problems.\n",
    "\n",
    "Use RNNs For:\n",
    "\n",
    "* Text data\n",
    "* Speech data\n",
    "* Classification prediction problems\n",
    "* Regression prediction problems\n",
    "* Generative models\n",
    "\n",
    "Recurrent neural networks are **not appropriate for tabular datasets** as you would see in a CSV file or spreadsheet. They are also not appropriate for image data input.\n",
    "[source](https://machinelearningmastery.com/when-to-use-mlp-cnn-and-rnn-neural-networks/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
